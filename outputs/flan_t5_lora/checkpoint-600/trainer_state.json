{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.7905138339920948,
  "eval_steps": 200,
  "global_step": 600,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.013175230566534914,
      "grad_norm": 9.089582443237305,
      "learning_rate": 7.82608695652174e-05,
      "loss": 42.5216,
      "step": 10
    },
    {
      "epoch": 0.026350461133069828,
      "grad_norm": 13.273231506347656,
      "learning_rate": 0.00016521739130434784,
      "loss": 43.3399,
      "step": 20
    },
    {
      "epoch": 0.039525691699604744,
      "grad_norm": 11.772955894470215,
      "learning_rate": 0.0001983695652173913,
      "loss": 41.4172,
      "step": 30
    },
    {
      "epoch": 0.052700922266139656,
      "grad_norm": 10.822589874267578,
      "learning_rate": 0.0001956521739130435,
      "loss": 37.7455,
      "step": 40
    },
    {
      "epoch": 0.06587615283267458,
      "grad_norm": 11.296880722045898,
      "learning_rate": 0.00019293478260869567,
      "loss": 36.6619,
      "step": 50
    },
    {
      "epoch": 0.07905138339920949,
      "grad_norm": 9.570931434631348,
      "learning_rate": 0.00019021739130434782,
      "loss": 34.2618,
      "step": 60
    },
    {
      "epoch": 0.0922266139657444,
      "grad_norm": 18.898488998413086,
      "learning_rate": 0.0001875,
      "loss": 28.5238,
      "step": 70
    },
    {
      "epoch": 0.10540184453227931,
      "grad_norm": 14.464706420898438,
      "learning_rate": 0.00018478260869565218,
      "loss": 27.2229,
      "step": 80
    },
    {
      "epoch": 0.11857707509881422,
      "grad_norm": 10.02048397064209,
      "learning_rate": 0.00018206521739130437,
      "loss": 23.4634,
      "step": 90
    },
    {
      "epoch": 0.13175230566534915,
      "grad_norm": 16.0568790435791,
      "learning_rate": 0.00017934782608695652,
      "loss": 20.0847,
      "step": 100
    },
    {
      "epoch": 0.14492753623188406,
      "grad_norm": 12.727888107299805,
      "learning_rate": 0.0001766304347826087,
      "loss": 17.0388,
      "step": 110
    },
    {
      "epoch": 0.15810276679841898,
      "grad_norm": 11.909480094909668,
      "learning_rate": 0.00017391304347826088,
      "loss": 15.364,
      "step": 120
    },
    {
      "epoch": 0.1712779973649539,
      "grad_norm": 16.312366485595703,
      "learning_rate": 0.00017119565217391304,
      "loss": 13.1425,
      "step": 130
    },
    {
      "epoch": 0.1844532279314888,
      "grad_norm": 10.576364517211914,
      "learning_rate": 0.00016847826086956522,
      "loss": 10.1758,
      "step": 140
    },
    {
      "epoch": 0.1976284584980237,
      "grad_norm": 24.73046875,
      "learning_rate": 0.0001657608695652174,
      "loss": 9.0393,
      "step": 150
    },
    {
      "epoch": 0.21080368906455862,
      "grad_norm": 2.9892265796661377,
      "learning_rate": 0.00016304347826086955,
      "loss": 7.896,
      "step": 160
    },
    {
      "epoch": 0.22397891963109354,
      "grad_norm": 2.6709413528442383,
      "learning_rate": 0.00016032608695652173,
      "loss": 7.0001,
      "step": 170
    },
    {
      "epoch": 0.23715415019762845,
      "grad_norm": 4.586677551269531,
      "learning_rate": 0.0001576086956521739,
      "loss": 6.604,
      "step": 180
    },
    {
      "epoch": 0.2503293807641634,
      "grad_norm": 2.019784927368164,
      "learning_rate": 0.0001548913043478261,
      "loss": 6.2127,
      "step": 190
    },
    {
      "epoch": 0.2635046113306983,
      "grad_norm": 1.7410333156585693,
      "learning_rate": 0.00015217391304347827,
      "loss": 5.8239,
      "step": 200
    },
    {
      "epoch": 0.2766798418972332,
      "grad_norm": 2.491849660873413,
      "learning_rate": 0.00014945652173913046,
      "loss": 5.4445,
      "step": 210
    },
    {
      "epoch": 0.2898550724637681,
      "grad_norm": 1.0790079832077026,
      "learning_rate": 0.00014673913043478264,
      "loss": 5.305,
      "step": 220
    },
    {
      "epoch": 0.30303030303030304,
      "grad_norm": 1.0177122354507446,
      "learning_rate": 0.0001440217391304348,
      "loss": 5.1114,
      "step": 230
    },
    {
      "epoch": 0.31620553359683795,
      "grad_norm": 0.702623188495636,
      "learning_rate": 0.00014130434782608697,
      "loss": 5.0299,
      "step": 240
    },
    {
      "epoch": 0.32938076416337286,
      "grad_norm": 0.9274431467056274,
      "learning_rate": 0.00013858695652173915,
      "loss": 4.9643,
      "step": 250
    },
    {
      "epoch": 0.3425559947299078,
      "grad_norm": 0.5500919818878174,
      "learning_rate": 0.0001358695652173913,
      "loss": 4.8705,
      "step": 260
    },
    {
      "epoch": 0.3557312252964427,
      "grad_norm": 0.9224012494087219,
      "learning_rate": 0.0001331521739130435,
      "loss": 4.8122,
      "step": 270
    },
    {
      "epoch": 0.3689064558629776,
      "grad_norm": 0.7167598009109497,
      "learning_rate": 0.00013043478260869567,
      "loss": 4.779,
      "step": 280
    },
    {
      "epoch": 0.3820816864295125,
      "grad_norm": 1.1796648502349854,
      "learning_rate": 0.00012771739130434782,
      "loss": 4.7563,
      "step": 290
    },
    {
      "epoch": 0.3952569169960474,
      "grad_norm": 1.138789176940918,
      "learning_rate": 0.000125,
      "loss": 4.6454,
      "step": 300
    },
    {
      "epoch": 0.40843214756258234,
      "grad_norm": 0.6479017734527588,
      "learning_rate": 0.00012228260869565218,
      "loss": 4.6606,
      "step": 310
    },
    {
      "epoch": 0.42160737812911725,
      "grad_norm": 0.8595011234283447,
      "learning_rate": 0.00011956521739130435,
      "loss": 4.601,
      "step": 320
    },
    {
      "epoch": 0.43478260869565216,
      "grad_norm": 1.8207911252975464,
      "learning_rate": 0.00011684782608695652,
      "loss": 4.5867,
      "step": 330
    },
    {
      "epoch": 0.4479578392621871,
      "grad_norm": 0.8512624502182007,
      "learning_rate": 0.0001141304347826087,
      "loss": 4.5248,
      "step": 340
    },
    {
      "epoch": 0.461133069828722,
      "grad_norm": 6.1239471435546875,
      "learning_rate": 0.00011141304347826087,
      "loss": 4.5296,
      "step": 350
    },
    {
      "epoch": 0.4743083003952569,
      "grad_norm": 0.7446771860122681,
      "learning_rate": 0.00010869565217391305,
      "loss": 4.4562,
      "step": 360
    },
    {
      "epoch": 0.4874835309617918,
      "grad_norm": 1.6374019384384155,
      "learning_rate": 0.00010597826086956521,
      "loss": 4.421,
      "step": 370
    },
    {
      "epoch": 0.5006587615283268,
      "grad_norm": 0.8853378295898438,
      "learning_rate": 0.00010326086956521738,
      "loss": 4.555,
      "step": 380
    },
    {
      "epoch": 0.5138339920948617,
      "grad_norm": 0.929172933101654,
      "learning_rate": 0.00010054347826086956,
      "loss": 4.3591,
      "step": 390
    },
    {
      "epoch": 0.5270092226613966,
      "grad_norm": 1.0273985862731934,
      "learning_rate": 9.782608695652174e-05,
      "loss": 4.3387,
      "step": 400
    },
    {
      "epoch": 0.5401844532279315,
      "grad_norm": 0.6727669835090637,
      "learning_rate": 9.510869565217391e-05,
      "loss": 4.2996,
      "step": 410
    },
    {
      "epoch": 0.5533596837944664,
      "grad_norm": 1.032495141029358,
      "learning_rate": 9.239130434782609e-05,
      "loss": 4.3554,
      "step": 420
    },
    {
      "epoch": 0.5665349143610013,
      "grad_norm": 0.7501848936080933,
      "learning_rate": 8.967391304347826e-05,
      "loss": 4.2374,
      "step": 430
    },
    {
      "epoch": 0.5797101449275363,
      "grad_norm": 0.6435204148292542,
      "learning_rate": 8.695652173913044e-05,
      "loss": 4.1877,
      "step": 440
    },
    {
      "epoch": 0.5928853754940712,
      "grad_norm": 1.413171410560608,
      "learning_rate": 8.423913043478261e-05,
      "loss": 4.1925,
      "step": 450
    },
    {
      "epoch": 0.6060606060606061,
      "grad_norm": 2.1033647060394287,
      "learning_rate": 8.152173913043478e-05,
      "loss": 4.1431,
      "step": 460
    },
    {
      "epoch": 0.619235836627141,
      "grad_norm": 0.9425073266029358,
      "learning_rate": 7.880434782608696e-05,
      "loss": 4.1321,
      "step": 470
    },
    {
      "epoch": 0.6324110671936759,
      "grad_norm": 1.059674859046936,
      "learning_rate": 7.608695652173914e-05,
      "loss": 4.0697,
      "step": 480
    },
    {
      "epoch": 0.6455862977602108,
      "grad_norm": 0.9766994714736938,
      "learning_rate": 7.336956521739132e-05,
      "loss": 4.0717,
      "step": 490
    },
    {
      "epoch": 0.6587615283267457,
      "grad_norm": 0.7665987610816956,
      "learning_rate": 7.065217391304349e-05,
      "loss": 4.014,
      "step": 500
    },
    {
      "epoch": 0.6719367588932806,
      "grad_norm": 1.0294746160507202,
      "learning_rate": 6.793478260869565e-05,
      "loss": 4.0387,
      "step": 510
    },
    {
      "epoch": 0.6851119894598156,
      "grad_norm": 0.7334180474281311,
      "learning_rate": 6.521739130434783e-05,
      "loss": 3.9785,
      "step": 520
    },
    {
      "epoch": 0.6982872200263505,
      "grad_norm": 0.7588258385658264,
      "learning_rate": 6.25e-05,
      "loss": 3.9546,
      "step": 530
    },
    {
      "epoch": 0.7114624505928854,
      "grad_norm": 0.9798223376274109,
      "learning_rate": 5.9782608695652175e-05,
      "loss": 3.9482,
      "step": 540
    },
    {
      "epoch": 0.7246376811594203,
      "grad_norm": 0.7258914709091187,
      "learning_rate": 5.706521739130435e-05,
      "loss": 3.931,
      "step": 550
    },
    {
      "epoch": 0.7378129117259552,
      "grad_norm": 0.655970573425293,
      "learning_rate": 5.4347826086956524e-05,
      "loss": 3.9045,
      "step": 560
    },
    {
      "epoch": 0.7509881422924901,
      "grad_norm": 1.0768135786056519,
      "learning_rate": 5.163043478260869e-05,
      "loss": 3.8775,
      "step": 570
    },
    {
      "epoch": 0.764163372859025,
      "grad_norm": 2.200139284133911,
      "learning_rate": 4.891304347826087e-05,
      "loss": 3.8487,
      "step": 580
    },
    {
      "epoch": 0.7773386034255599,
      "grad_norm": 0.8995884656906128,
      "learning_rate": 4.6195652173913046e-05,
      "loss": 3.8512,
      "step": 590
    },
    {
      "epoch": 0.7905138339920948,
      "grad_norm": 0.8057460784912109,
      "learning_rate": 4.347826086956522e-05,
      "loss": 3.8196,
      "step": 600
    }
  ],
  "logging_steps": 10,
  "max_steps": 759,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 224336963174400.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
